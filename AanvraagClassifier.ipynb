{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic classification of stadsarchief images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import keras.backend as K\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Input, Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "\n",
    "from stats import list_stats, show_train_curves, show_prediction_list, show_prediction_images\n",
    "# from stats import show_train_curves\n",
    "from data import load_data, split_data\n",
    "from image_display import show_image\n",
    "\n",
    "# Hot reload packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = (200, 200, 3);\n",
    "img_dim = (250, 250, 3);\n",
    "# img_dim = (300, 300, 3);\n",
    "# img_dim = (400, 400, 3);\n",
    "IMG_DIR = f'examples/aanvraag_besluit/resized/{img_dim[0]}x{img_dim[1]}/'\n",
    "LABEL_DIR = 'examples/aanvraag_besluit/labels/'\n",
    "\n",
    "\n",
    "[X, Y_yaml, ids] = load_data(IMG_DIR, LABEL_DIR)\n",
    "X = X / 255.  # normalize image data between 0 and 1\n",
    "Y_type = np.array([y.get('type') for y in Y_yaml])\n",
    "\n",
    "print(f\"shape X: {X.shape}\")\n",
    "print(f\"shape Y: {Y_type.shape}\")\n",
    "print(f\"len ids: {len(ids)}\")\n",
    "\n",
    "def shuffle(X, Y, ids):\n",
    "    assert isinstance(ids, list)\n",
    "    indices = np.random.permutation(X.shape[0])\n",
    "    X_shuffled = X[indices]\n",
    "    Y_shuffled = Y[indices]\n",
    "    ids_shuffled = [ids[i] for i in indices]\n",
    "    return (X_shuffled, Y_shuffled, ids_shuffled)\n",
    "\n",
    "# print('shuffling X, Y and ids')\n",
    "# X_shuffled, Y_shuffled, ids_shuffled = shuffle(X, Y_type, ids)\n",
    "# X = X_shuffled\n",
    "# Y_type = Y_shuffled\n",
    "# ids = ids_shuffled\n",
    "\n",
    "print(f\"shape X: {X.shape}\")\n",
    "print(f\"shape Y: {Y_type.shape}\")\n",
    "print(f\"len ids: {len(ids)}\")\n",
    "\n",
    "list_stats(Y_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert string to idx\n",
    "types = list(set(Y_type))\n",
    "num_classes = len(types)\n",
    "print(f\"number of classes: {num_classes}\")\n",
    "print(f\"types encountered: {types}\")\n",
    "\n",
    "def convert_to_index(Y, types):\n",
    "    return np.array([types.index(y) for y in Y])\n",
    "\n",
    "Yind = convert_to_index(Y_type, types)\n",
    "print(Y_type[:3])\n",
    "print(Yind[:3])\n",
    "\n",
    "list_stats(Yind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = keras.utils.to_categorical(Yind, num_classes)  # convert class vectors to binary class matrices\n",
    "print(Yind.shape)\n",
    "print(Y.shape)\n",
    "print(Y[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split to train and test\n",
    "SPLIT = 0.8\n",
    "\n",
    "# (X_train, Y_train), (X_test, Y_test) = split_data(X, Yscaled, SPLIT)\n",
    "(X_train, Y_train, ids_train), (X_test, Y_test, ids_test) = split_data(X, Y, ids, SPLIT)\n",
    "\n",
    "print(\"split data shapes:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"Y_train: {Y_train.shape}\")\n",
    "print(f\"X_test: {X_test.shape}\")\n",
    "print(f\"Y_test: {Y_test.shape}\")\n",
    "print(f\"ids_train: {len(ids_train)}\")\n",
    "print(f\"ids_test: {len(ids_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def build_model(num_classes, img_dim):\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "#                      activation='relu',\n",
    "#                      input_shape=img_dim))\n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(num_classes, activation='softmax'))\n",
    "#     return model\n",
    "\n",
    "\n",
    "def build_model(num_classes, img_dim):\n",
    "    print(img_dim)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, kernel_size=(3, 3), activation='linear', input_shape=img_dim))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='linear'))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='linear', kernel_initializer = RandomUniform()))\n",
    "    model.add(LeakyReLU(alpha=0.1))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "\n",
    "def build_medium_size(num_classes, img_dim):\n",
    "    # src: https://www.learnopencv.com/image-classification-using-convolutional-neural-networks-in-keras/\n",
    "    print(img_dim)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation='relu', input_shape=img_dim))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = build_model(num_classes, img_dim)\n",
    "# model = build_vgg16(num_classes, img_dim)\n",
    "# model = build_medium_size(num_classes, img_dim)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "batch_size = 200\n",
    "epochs = 100\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        zoom_range=0.1,        # randomly zoom into images\n",
    "        rotation_range=5,      # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,# randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False    # randomly flip images\n",
    ")\n",
    " \n",
    "    \n",
    "def compile_model(model):\n",
    "    assert(K.image_data_format() == 'channels_last')\n",
    "    model.compile(\n",
    "        loss=keras.losses.categorical_crossentropy,\n",
    "#         optimizer=keras.optimizers.Adadelta(),\n",
    "#         optimizer='rmsprop',\n",
    "        optimizer=keras.optimizers.Adam(),        \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "def train(model, X_train, Y_train, X_test, Y_test, batch_size, epochs):\n",
    "    compile_model(model)\n",
    "    history = model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(X_test, Y_test)\n",
    "           )\n",
    "    return history\n",
    "\n",
    "def train_gen(model, X_train, Y_train, X_test, Y_test, batch_size, epochs):\n",
    "    compile_model(model)\n",
    "    history = model.fit_generator(\n",
    "        datagen.flow(X_train,\n",
    "                     Y_train,\n",
    "                     batch_size=batch_size\n",
    "        ),\n",
    "        steps_per_epoch=int(np.ceil(X_train.shape[0] / float(batch_size))),\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_test, Y_test),\n",
    "        workers=4\n",
    "    )\n",
    "    return history\n",
    "history = train(model, X_train, Y_train, X_test, Y_test, batch_size, epochs)\n",
    "# history = train_gen(model, X_train, Y_train, X_test, Y_test, batch_size, epochs)\n",
    "\n",
    "\n",
    "show_train_curves(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(X_train, Y_train, verbose=1)\n",
    "print('Train loss:', round(score[0], 3))\n",
    "print(f'Train accuracy: {round(score[1] * 100, 2)}%')\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', round(score[0], 3))\n",
    "print(f'Test accuracy: {round(score[1] * 100, 2)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"types: {types}\")\n",
    "\n",
    "print(\"train predictions, truth\")\n",
    "predictions_train =  model.predict(X_train, verbose=1)\n",
    "show_prediction_list(predictions_train, Y_train)\n",
    "\n",
    "print(\"test predictions, truth\")\n",
    "predictions_test = model.predict(X_test, verbose=1)\n",
    "show_prediction_list(predictions_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 11\n",
    "print(ids_test[idx])\n",
    "show_image(X_test, idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y_train_idx = np.argmax(Y_train, axis=1)        \n",
    "Y_test_idx = np.argmax(Y_test, axis=1)\n",
    "\n",
    "print(\"train set:\")\n",
    "show_prediction_images(X_train, Y_train_idx, ids_train, predictions_train, types, 10)\n",
    "\n",
    "print(\"test set:\")\n",
    "show_prediction_images(X_test, Y_test_idx, ids_test, predictions_test, types, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
