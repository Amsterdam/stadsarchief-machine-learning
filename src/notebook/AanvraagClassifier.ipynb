{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aanvraag / besluit classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug commands to see if Tensorflow GPU is supported\n",
    "# from keras import backend as K\n",
    "# print(K.tensorflow_backend._get_available_gpus())\n",
    "\n",
    "# from tensorflow.python.client import device_lib\n",
    "# print(device_lib.list_local_devices())\n",
    "\n",
    "import tensorflow as tf\n",
    "# sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import shutil\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras_metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.calibration import calibration_curve\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "from datasets.example.aanvraag_besluit.load_data import load_data_aanvraag, load_getting_started_data\n",
    "\n",
    "from src.stats import list_stats, show_train_curves, show_prediction_list, show_prediction_images\n",
    "from src.data import split_data\n",
    "from src.image_display import show_image\n",
    "from src import models as own_models\n",
    "from src.processing.TargetEncoder import TargetEncoder\n",
    "from src.processing.ImageFeatureEncoder import ImageFeatureEncoder\n",
    "\n",
    "# Hot reload packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.getLogger().setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tensorflow GPU memory usage to on the fly rather than preallocate.\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, weights and transformations persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR='./output/model/'\n",
    "TRANSFORM_DIR=os.path.join(MODEL_DIR, 'transform/')\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(TRANSFORM_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = (250, 250, 3);\n",
    "\n",
    "[\n",
    "    [Xtrain_raw, Ytrain_raw, Ztrain_raw],\n",
    "    [Xvalid_raw, Yvalid_raw, Zvalid_raw],\n",
    "    _test,\n",
    "] = load_data_aanvraag(img_dim)\n",
    "\n",
    "print(f\"shape Xtrain: {Xtrain_raw.shape}\")\n",
    "print(f\"shape Ytrain: {Ytrain_raw.shape}\")\n",
    "print(f\"shape Ztrain: {Ztrain_raw.shape}\")\n",
    "\n",
    "print(f\"shape Xvalid: {Xvalid_raw.shape}\")\n",
    "print(f\"shape Yvalid: {Yvalid_raw.shape}\")\n",
    "print(f\"shape Zvalid: {Zvalid_raw.shape}\")\n",
    "\n",
    "print(\"not using (hold out) test set of shape: \", _test[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{Xtrain_raw.nbytes / 1024**2}MB')\n",
    "Xtrain_raw.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "### feature preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Meta data AND image transformations\n",
    "# # Preprocess (encode, transform features and labels)\n",
    "# transformer = Transformer()\n",
    "\n",
    "# Xdata_mix = Xtrain_raw[1].append(Xvalid_raw[1])\n",
    "# transformer.fit(Xdata_mix)\n",
    "\n",
    "# Xtrain = preprocess_X(Xtrain_raw[0], Xtrain_raw[1], transformer)\n",
    "# Xvalid = preprocess_X(Xvalid_raw[0], Xvalid_raw[1], transformer)\n",
    "# # print(Xtrain[1][:4])\n",
    "# # print(transformer.decode(Xtrain[1][:4]))\n",
    "# print(Xvalid[1][:4])\n",
    "# print(transformer.decode(Xvalid[1][:4]))\n",
    "\n",
    "# num_features = Xtrain[1].shape[1]\n",
    "# print(Xvalid[1].shape)\n",
    "# assert Xvalid[1].shape[1] == num_features\n",
    "# del Xdata_mix\n",
    "\n",
    "# Preprocess (encode, transform features and labels)\n",
    "\n",
    "imageEncoder = ImageFeatureEncoder()\n",
    "\n",
    "imageEncoder.fit(Xtrain_raw)\n",
    "print('fitted')\n",
    "\n",
    "Xtrain = imageEncoder.transform(Xtrain_raw)\n",
    "Xvalid = imageEncoder.transform(Xvalid_raw)\n",
    "print('Xtrain.shape: ', Xtrain.shape)\n",
    "print('Xvalid.shape: ', Xvalid.shape)\n",
    "\n",
    "# print(Xvalid[:4])\n",
    "imageEncoder.save(TRANSFORM_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{Xtrain.nbytes / 1024**2}MB')\n",
    "Xtrain.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = list(set(Ztrain_raw.ravel()))\n",
    "print(classes)\n",
    "num_classes = 2\n",
    "assert len(classes) == num_classes\n",
    "\n",
    "\n",
    "print('')\n",
    "print('--- TRAIN ---')\n",
    "list_stats(Ztrain_raw.ravel())\n",
    "\n",
    "print('')\n",
    "print('--- VALID ---')\n",
    "list_stats(Zvalid_raw.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enc = preprocessing.LabelEncoder()  # outputs 1d array, binary classification\n",
    "encoder = TargetEncoder()\n",
    "\n",
    "# assert Ztrain_raw.ndim == 1\n",
    "encoder.fit(Ztrain_raw)\n",
    "\n",
    "print('Ztrain_raw shape: ', Ztrain_raw.shape)\n",
    "print('Ztrain_raw[:10]: ', Ztrain_raw[:10])\n",
    "\n",
    "Ztrain = encoder.transform(Ztrain_raw).toarray()\n",
    "Zvalid = encoder.transform(Zvalid_raw).toarray()\n",
    "print('Ztrain: ', Ztrain.shape)\n",
    "print('Zvalid: ', Zvalid.shape)\n",
    "print('Ztrain: ', Ztrain[:10])\n",
    "\n",
    "print(f'inverse transform for example: {encoder.inverse_transform([[1, 0.5]])}')\n",
    "\n",
    "encoder.save(TRANSFORM_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show mapping from string to one hot:\n",
    "labels = np.array([['aanvraag'], ['other']])\n",
    "print(f'labels:\\n{labels}')\n",
    "print(f'encoded:\\n{encoder.transform(label).toarray()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = own_models.build_multi_feature(num_classes, img_dim, num_features)\n",
    "model = own_models.create_cnn(img_dim, num_classes)\n",
    "# model = own_models.create_cnn_deep(img_dim, num_classes)\n",
    "# model = own_models.create_mlp(num_features, num_classes)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "epochs = 100\n",
    "\n",
    "class_weight = {\n",
    "    0: 1.0,  # aanvraag error is 1.5 weight of other error (focus on learning recall)\n",
    "    1: 1.0, # other\n",
    "}\n",
    "\n",
    "run_name = '/larger_train_en_test_set'\n",
    "LOG_DIR = f'./logs{run_name}'\n",
    "shutil.rmtree(LOG_DIR, ignore_errors=True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    zoom_range=0.1,        # randomly zoom into images\n",
    "    rotation_range=10,      # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.1,# randomly shift images vertically (fraction of total height)\n",
    "    shear_range=2.0,  # in degrees\n",
    "    channel_shift_range=0.1,\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False    # randomly flip images\n",
    "    \n",
    "    # Heavy augmentation\n",
    "#         zoom_range=0.15,        # randomly zoom into images\n",
    "#         rotation_range=15,      # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#         width_shift_range=0.15, # randomly shift images horizontally (fraction of total width)\n",
    "#         height_shift_range=0.15,# randomly shift images vertically (fraction of total height)\n",
    "#         shear_range=4.0,  # in degrees\n",
    "#         channel_shift_range=0.15,\n",
    "#         horizontal_flip=False,  # randomly flip images\n",
    "#         vertical_flip=False    # randomly flip images\n",
    ")\n",
    "\n",
    "tbCallBack = keras.callbacks.TensorBoard(\n",
    "    log_dir=LOG_DIR,\n",
    "    histogram_freq=0,\n",
    "    write_graph=True,\n",
    "    write_images=True\n",
    ")\n",
    "\n",
    "terminateCB = tf.keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "\n",
    "def is_binary(model):\n",
    "    n_classes = model.get_layer('output').output_shape[1]\n",
    "    return n_classes == 1\n",
    "    \n",
    "def compile_model(model):\n",
    "    assert(K.image_data_format() == 'channels_last')\n",
    "    \n",
    "#     if is_binary(model):\n",
    "#         loss= keras.losses.binary_crossentropy\n",
    "#     else:\n",
    "    loss=keras.losses.categorical_crossentropy\n",
    "    \n",
    "    model.compile(\n",
    "        loss=loss,\n",
    "#         optimizer=keras.optimizers.Adadelta(),\n",
    "#         optimizer='rmsprop',\n",
    "#         optimizer='sgd',\n",
    "#         optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "#         optimizer=keras.optimizers.Adam(),        \n",
    "#         optimizer=keras.optimizers.Adam(lr=0.0003),\n",
    "        optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "#         optimizer=keras.optimizers.Adam(lr=0.00003),\n",
    "#         metrics=['accuracy', keras_metrics.recall()]\n",
    "        metrics=['accuracy', keras_metrics.binary_recall(label=0)]\n",
    "\n",
    "    )\n",
    "\n",
    "def train(model, X_train, Z_train, X_valid, Z_valid, batch_size, epochs):\n",
    "    compile_model(model)\n",
    "    \n",
    "    history = model.fit(X_train, Z_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              validation_data=(X_valid, Z_valid),\n",
    "              class_weight=class_weight,\n",
    "              callbacks=[tbCallBack, terminateCB]\n",
    "           )\n",
    "    return history\n",
    "\n",
    "def train_gen(model, X_train, Z_train, X_valid, Z_valid, batch_size, epochs):\n",
    "    compile_model(model)\n",
    "\n",
    "#     with tf.Session() as s:\n",
    "#         s.run(tf.global_variables_initializer())\n",
    "    history = model.fit_generator(\n",
    "        datagen.flow(X_train,\n",
    "                     Z_train,\n",
    "                     batch_size=batch_size\n",
    "        ),\n",
    "        steps_per_epoch=int(np.ceil(X_train.shape[0] / float(batch_size))),\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_valid, Z_valid),\n",
    "        class_weight=class_weight,\n",
    "        workers=4,\n",
    "        callbacks=[tbCallBack, terminateCB]\n",
    "    )\n",
    "    return history\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# model = own_models.create_cnn_deep_d(img_dim, num_classes)\n",
    "\n",
    "# Combined data\n",
    "# history = train(model, Xtrain, Ytrain, Xvalid, Yvalid, batch_size, epochs)\n",
    "\n",
    "# Meta data\n",
    "# model = own_models.create_mlp(num_features, num_classes)\n",
    "# history = train(model, Xtrain[1], Ytrain, Xvalid[1], Yvalid, batch_size, epochs)\n",
    "\n",
    "# Img data\n",
    "model = own_models.create_cnn(img_dim, num_classes)\n",
    "# history = train(model, Xtrain[0], Ytrain, Xvalid[0], Yvalid, batch_size, epochs)\n",
    "history = train_gen(model, Xtrain, Ztrain, Xvalid, Zvalid, batch_size, epochs)\n",
    "\n",
    "show_train_curves(history)\n",
    "\n",
    "difference = time.time() - t0\n",
    "print(f'time: {difference} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.evaluate(Xtrain, Ztrain, verbose=1)\n",
    "print('Train loss:', round(train_score[0], 3))\n",
    "print(f'Train accuracy: {round(train_score[1] * 100, 2)}%')\n",
    "\n",
    "valid_score = model.evaluate(Xvalid, Zvalid, verbose=1)\n",
    "print('Test loss:', round(valid_score[0], 3))\n",
    "valid_acc_str = f'{round(valid_score[1] * 100, 2)}%'\n",
    "print(f'Test accuracy: {valid_acc_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"types: {classes}\")\n",
    "\n",
    "print(\"train predictions, truth\")\n",
    "predictions_train =  model.predict(Xtrain, verbose=1)\n",
    "show_prediction_list(predictions_train, Ztrain)\n",
    "\n",
    "print(\"test predictions, truth\")\n",
    "predictions_valid = model.predict(Xvalid, verbose=1)\n",
    "show_prediction_list(predictions_valid, Zvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 11\n",
    "# id = Yvalid_raw[idx, 2]\n",
    "# image = Xvalid_raw[idx]\n",
    "# print(id)\n",
    "# show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Z_train_idx = np.argmax(Z_train, axis=1)        \n",
    "# Z_test_idx = np.argmax(Z_test, axis=1)\n",
    "\n",
    "print(\"train set:\")\n",
    "show_prediction_images(\n",
    "    Xtrain_raw,\n",
    "    Ztrain,\n",
    "    predictions_train,\n",
    "    Ytrain_raw[:, 2],\n",
    "    encoder,\n",
    "    10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"test set:\")\n",
    "show_prediction_images(\n",
    "    Xvalid_raw,\n",
    "    Zvalid,\n",
    "    predictions_valid,\n",
    "    Yvalid_raw[:, 2],\n",
    "    encoder,\n",
    "    50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def multi_class_to_binary(class_true: np.ndarray, class_pred: np.ndarray):\n",
    "#     # Converting to probablilty that Y_true == 1\n",
    "#     assert class_true.shape[1] == 2  # 2 classes\n",
    "#     assert class_pred.shape[1] == 2  # 2 classes\n",
    "#     assert class_true.shape[0] == class_pred.shape[0]\n",
    "    \n",
    "#     y_true = np.argmax(class_true, axis=1)\n",
    "    \n",
    "# #     pred_ids = np.argmax(class_pred, axis=1)\n",
    "# #     y_prob = class_pred[range(class_pred.shape[0]), pred_ids]\n",
    "#     y_prob = class_pred[:, 1]\n",
    "#     assert y_true.shape == y_prob.shape\n",
    "#     return [y_true, y_prob]\n",
    "    \n",
    "# [y_true, y_prob] = multi_class_to_binary(Y_test, predictions_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(Yvalid[0:20])\n",
    "# print(np.round(predictions_valid[0:20], 3))\n",
    "# predictions_valid.shape\n",
    "# # print(np.round(y_prob[0:10], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # class_pred = predictions_test\n",
    "# # pred_ids = np.argmax(class_pred, axis=1)\n",
    "# # y_prob = class_pred[range(class_pred.shape[0]), pred_ids]\n",
    "# y_prob = predictions_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reference https://scikit-learn.org/stable/auto_examples/calibration/plot_calibration_curve.html#sphx-glr-auto-examples-calibration-plot-calibration-curve-py\n",
    "\n",
    "# n_bins = 5\n",
    "\n",
    "# print(f'accuracy: {test_acc_str}')\n",
    "# conf_avg = np.average(predictions_test)\n",
    "# conf_avg_str = f'{round(conf_avg * 100, 2)}%'\n",
    "# print(f'confidence avg: {conf_avg_str}')\n",
    "\n",
    "# def draw_confidence_histogram(y_prob, n_bins):\n",
    "#     plt.figure()\n",
    "#     plt.title('Confidence histogram')\n",
    "#     plt.xlabel(\"Confidence\")\n",
    "#     plt.ylabel(\"Sample count\")\n",
    "#     plt.hist(y_prob, bins=n_bins)    \n",
    "# draw_confidence_histogram(y_prob, n_bins=n_bins)\n",
    "\n",
    "# def draw_reliability_curve(y_true, y_prob, n_bins):\n",
    "#     plt.figure()\n",
    "#     plt.title('Reliability curve')\n",
    "#     plt.xlabel(\"Confidence\")\n",
    "#     plt.ylabel(\"Accuracy\")\n",
    "#     [prob_true_bins, prob_pred_bins] = calibration_curve(y_true, y_prob, n_bins=n_bins)\n",
    "\n",
    "#     plt.plot([0, 1], [0, 1], \"k:\", label=\"Perfectly calibrated\")\n",
    "#     plt.plot(prob_pred_bins, prob_true_bins, marker='s')\n",
    "# draw_reliability_curve(y_true, y_prob, n_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, recall_score, accuracy_score\n",
    "\n",
    "conf_threshold = 0.60\n",
    "labels = ['aanvraag', 'other']\n",
    "\n",
    "# Stats calculation by hand\n",
    "# assert len(labels) == 2\n",
    "# # in binary case confusion matrix is true postive, true negative etc.\n",
    "# tn, fp, fn, tp = confusion.ravel()\n",
    "# # Own recall calculation for sanity check\n",
    "# recall = tp / (tp + fn)\n",
    "# print(f'recall: {recall}')\n",
    "\n",
    "# ROC curve\n",
    "# assert len(labels) == 2  # only works for binary case\n",
    "# scores = np.where(prob[:,0]>conf_threshold, 0,1)\n",
    "# print(y_true[:10, :])\n",
    "# print((predictions_valid[:10, :]).round(2))\n",
    "# metrics.roc_curve(y_true, scores, pos_label=2)\n",
    "\n",
    "#\n",
    "# \n",
    "#\n",
    "def split_bool_arrays(predictions: np.ndarray, threshold, verbose=False):\n",
    "    assert predictions.shape[1] == 2, 'expecting binary prediction in one hot format'\n",
    "    \n",
    "#     y_pred_class = np.argmax(predictions, axis=1)\n",
    "    y_pred_conf = np.amax(predictions, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(y_pred_conf.round(2)[:10])\n",
    "    \n",
    "    certain = y_pred_conf >= threshold\n",
    "    uncertain = np.invert(certain)\n",
    "    return [certain, uncertain]\n",
    "\n",
    "def split_uncertain(predictions: np.ndarray, threshold, elements, verbose=False):\n",
    "    \"\"\"\n",
    "    Split all elements into certain and uncertain buckets\n",
    "    \n",
    "    @return [[elem1_certain, elem1_uncertain], ...]\n",
    "    \"\"\"\n",
    "    for element in elements:\n",
    "        assert element.shape[0] == predictions.shape[0], 'number of an element not equal to number of predictions'\n",
    "    \n",
    "    [certain, uncertain] = split_bool_arrays(predictions, threshold, verbose=verbose)\n",
    "    \n",
    "    results = []\n",
    "    for element in elements:\n",
    "        certain_bucket = element[certain]\n",
    "        uncertain_bucket = element[uncertain]\n",
    "        results.append([certain_bucket, uncertain_bucket])\n",
    "    return results\n",
    "    \n",
    "results = split_uncertain(predictions_valid, conf_threshold, [Xvalid_raw, Yvalid_raw, Zvalid, predictions_valid])\n",
    "print('image certain shape: ', results[0][0].shape)\n",
    "print('image uncertain shape: ', results[0][1].shape)\n",
    "print('meta certain shape: ', results[1][0].shape)\n",
    "print('meta uncertain shape: ', results[1][1].shape)\n",
    "\n",
    "[\n",
    "    _, # img\n",
    "    _, # meta\n",
    "    Zvalid_buckets, # true\n",
    "    Zvalid_pred_buckets, # prediction\n",
    "] = results\n",
    "\n",
    "#\n",
    "\n",
    "def print_missing_types_error(unique_types: list, expected: list, name: str):\n",
    "    print(f'{name} samples do not reflect all types, recall, precision and T1 scores therefor do not make much sense.')\n",
    "    print(f'{name} types: {unique_types}, expected {expected}')\n",
    "    print('Classification report generation skipped.')\n",
    "\n",
    "\n",
    "def create_reports(y_true_oh: np.ndarray, y_pred_oh: np.ndarray):\n",
    "    assert y_true_oh.shape == y_pred_oh.shape\n",
    "    assert y_true_oh.shape[1] == 2, 'expecting binary one hot inputs'\n",
    "    y_true = encoder.inverse_transform(y_true_oh)\n",
    "    y_pred = encoder.inverse_transform(y_pred_oh)\n",
    "    \n",
    "    is_correct=y_true == y_pred\n",
    "    \n",
    "#     confusion = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "#     plt.imshow(confusion, cmap='binary', interpolation='None')\n",
    "#     plt.show()\n",
    "#     print(f'confusion matrix:\\n{confusion}')\n",
    "    y_true_pd = pd.Series(y_true.ravel())\n",
    "    y_pred_pd = pd.Series(y_pred.ravel())\n",
    "    crosstab = pd.crosstab(y_true_pd, y_pred_pd, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "    \n",
    "    report = None\n",
    "    true_types = np.unique(y_true_pd)\n",
    "    pred_types = np.unique(y_pred_pd)\n",
    "    if len(true_types) < len(labels):\n",
    "        print_missing_types_error(true_types, labels, 'True')\n",
    "    elif len(pred_types) < len(labels):\n",
    "        print_missing_types_error(pred_types, labels, 'Pred')\n",
    "    else:\n",
    "        report = classification_report(y_true, y_pred, labels=labels)\n",
    "\n",
    "    return [crosstab, report, is_correct]\n",
    "\n",
    "\n",
    "def show_reports(y_true_oh: np.ndarray, y_pred_oh: np.ndarray):\n",
    "    if len(y_true_oh) == 0 or len(y_pred_oh) == 0:\n",
    "        print(\"No results to show\")\n",
    "        return\n",
    "    [crosstab, report, is_correct] = create_reports(y_true_oh, y_pred_oh)\n",
    "    print(crosstab)\n",
    "    \n",
    "    if (report):\n",
    "        print()\n",
    "        print(report)\n",
    "    \n",
    "    return is_correct\n",
    "    \n",
    "\n",
    "print()\n",
    "print('--- certain bucket stats ---')\n",
    "show_reports(Zvalid_buckets[0], Zvalid_pred_buckets[0])\n",
    "\n",
    "print()\n",
    "print('--- uncertain bucket stats ---')\n",
    "show_reports(Zvalid_buckets[1], Zvalid_pred_buckets[1])\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "\n",
    "predictions = predictions_valid\n",
    "\n",
    "def show_results(threshold):\n",
    "    ids = Yvalid_raw[:, 2]\n",
    "    total = predictions.shape[0]\n",
    "    [certain, uncertain] = split_bool_arrays(predictions, threshold)\n",
    "    certain_count = np.sum(certain)\n",
    "    uncertain_count = np.sum(uncertain)\n",
    "#     print(certain[:10])\n",
    "#     print(uncertain[:10])\n",
    "    \n",
    "    # Show counts of split\n",
    "    certain_percentage = certain_count/total*100\n",
    "    uncertain_percentage = uncertain_count/total*100\n",
    "    counts_df = pd.DataFrame([\n",
    "        [certain_count, uncertain_count, total],\n",
    "        [certain_percentage, uncertain_percentage, 100.0]\n",
    "    ],\n",
    "                      columns=['certain', 'uncertain', 'total'],\n",
    "                      index=['absolute', 'relative'])\n",
    "    \n",
    "    # Show metrics of splits\n",
    "    [\n",
    "        Ytrue_buckets,\n",
    "        Ypred_buckets,\n",
    "        ids_buckets,\n",
    "    ] = split_uncertain(predictions, threshold, [Zvalid, predictions_valid, ids])\n",
    "    \n",
    "    \n",
    "    certain_not_empty = Ytrue_buckets[0].shape[0] > 0\n",
    "    if certain_not_empty:\n",
    "        y_true = encoder.inverse_transform(Ytrue_buckets[0])\n",
    "        y_pred = encoder.inverse_transform(Ypred_buckets[0])\n",
    "        certain_accuracy = accuracy_score(y_true, y_pred)\n",
    "        certain_recall = recall_score(y_true, y_pred, pos_label='aanvraag')    \n",
    "        print(f'certain examples:\\t\\t{color.BOLD}{round(certain_percentage, 1)}%{color.END}', end='')\n",
    "        print(f'\\t-> recall aanvraag: {color.BOLD}{round(certain_recall*100, 2)}%{color.END}', end='')\n",
    "        print(f', accuracy aanvraag: {color.BOLD}{round(certain_accuracy*100, 2)}%{color.END}')\n",
    "    else:\n",
    "        print(f'certain examples:\\t\\t{color.BOLD}{round(certain_percentage, 1)}%{color.END}')\n",
    "    print(f'uncertain examples:\\t\\t{color.BOLD}{round(uncertain_percentage, 1)}%{color.END}')\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print(counts_df.round(2))\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print(f'{color.BOLD}## Certain examples{color.END}')\n",
    "    if certain_not_empty:\n",
    "        certain_is_correct = show_reports(Ytrue_buckets[0], Ypred_buckets[0])\n",
    "    else:\n",
    "        print('no data')\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print(f'{color.BOLD}## Uncertain examples{color.END}')\n",
    "    if Ytrue_buckets[1].shape[0] == 0:\n",
    "        print('no data')\n",
    "    else:\n",
    "        uncertain_is_correct = show_reports(Ytrue_buckets[1], Ypred_buckets[1])\n",
    "    \n",
    "    \n",
    "    print('## Certain errors')\n",
    "    certain_ids = ids_buckets[0]\n",
    "    certain_ids.shape = (certain_ids.size, 1)\n",
    "    certain_is_incorrect = np.invert(certain_is_correct)\n",
    "    \n",
    "    show_max = 50\n",
    "    incorrect = certain_ids[certain_is_incorrect]\n",
    "    print(f'incorrect ids[:{show_max}]:')\n",
    "    print('\\n'.join(incorrect[:show_max]))\n",
    "\n",
    "\n",
    "widget = widgets.FloatSlider(\n",
    "    value=0.9,\n",
    "    min=0.5,\n",
    "    max=1.0,\n",
    "    step=0.005,\n",
    "    continuous_update=False,\n",
    "    description='Threshold:',\n",
    "    readout=True,\n",
    "    readout_format='.3f',\n",
    ")\n",
    "\n",
    "interact(show_results, threshold=widget);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_overview(Y_oh, pred_oh, references, encoder):\n",
    "    Y_class = encoder.inverse_transform(Y_oh)\n",
    "    pred_class = encoder.inverse_transform(pred_oh)\n",
    "    \n",
    "    data = {'reference': references, 'label': Y_class[:, 0], 'prediction': pred_class[:, 0]}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "DIR = './output'\n",
    "os.makedirs(DIR, exist_ok=True)\n",
    "\n",
    "df = predictions_overview(Ztrain, predictions_train, Ytrain_raw[:, 2], encoder)\n",
    "df.to_csv(os.path.join(DIR, 'train_predictions.csv'))\n",
    "print('---TRAIN---')\n",
    "print(df)\n",
    "\n",
    "df = predictions_overview(Zvalid, predictions_valid, Yvalid_raw[:, 2], encoder)\n",
    "df.to_csv(os.path.join(DIR, 'validation_predictions.csv'))\n",
    "print('---VALID---')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_model(model, directory):\n",
    "    model_json = model.to_json()\n",
    "    json_path = os.path.join(directory, \"model.json\")\n",
    "    weights_path = os.path.join(directory, \"weights.h5\")\n",
    "    with open(json_path, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(weights_path)\n",
    "    print('done')\n",
    "\n",
    "write_model(model, MODEL_DIR)\n",
    "print(f\"Model written to {MODEL_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
