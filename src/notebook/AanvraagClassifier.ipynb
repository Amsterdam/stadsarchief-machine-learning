{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aanvraag / besluit classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hot reload packages\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "\n",
    "# Debug commands to see if Tensorflow GPU is supported\n",
    "print(f'gpus: {K.tensorflow_backend._get_available_gpus()}')\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(f'local devices: {device_lib.list_local_devices()}')\n",
    "\n",
    "# Set tensorflow GPU memory usage to on demand rather than preallocate.\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "K.tensorflow_backend.set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import shutil\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import keras_metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.calibration import calibration_curve\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    " \n",
    "from datasets.load_data import load_data_aanvraag, load_getting_started_data\n",
    "\n",
    "from src.stats import list_stats, show_train_curves, show_prediction_list, show_prediction_images\n",
    "from src.data import split_data\n",
    "from src.image_display import show_image\n",
    "from src import models as own_models\n",
    "from src.processing.TargetEncoder import TargetEncoder\n",
    "from src.processing.ImageFeatureEncoder import ImageFeatureEncoder\n",
    "from src.util.np_size import display_MB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show log output in Notebook\n",
    "import logging\n",
    "import sys\n",
    "log_level = logging.INFO\n",
    "root = logging.getLogger()\n",
    "handler = logging.StreamHandler(sys.stdout)\n",
    "handler.setLevel(log_level)\n",
    "root.addHandler(handler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model, weights and transformations persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_DIR='./output/model/'\n",
    "TRANSFORM_DIR=os.path.join(MODEL_DIR, 'transform/')\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "os.makedirs(TRANSFORM_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dim = (250, 250, 3);\n",
    "\n",
    "[\n",
    "    [Xtrain_raw, Ytrain_raw, Ztrain_raw],\n",
    "    [Xvalid_raw, Yvalid_raw, Zvalid_raw],\n",
    "    _test,\n",
    "] = load_data_aanvraag(img_dim)\n",
    "\n",
    "print(f\"shape Xtrain: {Xtrain_raw.shape}\")\n",
    "print(f\"shape Ytrain: {Ytrain_raw.shape}\")\n",
    "print(f\"shape Ztrain: {Ztrain_raw.shape}\")\n",
    "\n",
    "print(f\"shape Xvalid: {Xvalid_raw.shape}\")\n",
    "print(f\"shape Yvalid: {Yvalid_raw.shape}\")\n",
    "print(f\"shape Zvalid: {Zvalid_raw.shape}\")\n",
    "\n",
    "print(\"not using (hold out) test set of shape: \", _test[0].shape)\n",
    "\n",
    "print('training set size:')\n",
    "display_MB(Xtrain_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess\n",
    "### feature preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "imageEncoder = ImageFeatureEncoder()\n",
    "\n",
    "imageEncoder.fit(Xtrain_raw)\n",
    "print('fitted encoder to training set')\n",
    "\n",
    "print('transforming training set...')\n",
    "Xtrain = imageEncoder.transform(Xtrain_raw)\n",
    "print('transforming validation set...')\n",
    "Xvalid = imageEncoder.transform(Xvalid_raw)\n",
    "print('Xtrain.shape: ', Xtrain.shape)\n",
    "print('Xvalid.shape: ', Xvalid.shape)\n",
    "display_MB(Xtrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "classes = list(set(Ztrain_raw.ravel()))\n",
    "valid_classes = list(set(Ztrain_raw.ravel()))\n",
    "assert len(classes) == num_classes, f'{len(classes)} classes in training set: {classes}, expected: {num_classes}'\n",
    "\n",
    "print('')\n",
    "print('--- Train ---')\n",
    "list_stats(Ztrain_raw.ravel())\n",
    "\n",
    "print('')\n",
    "print('--- Valid ---')\n",
    "list_stats(Zvalid_raw.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelEncoder = TargetEncoder()\n",
    "\n",
    "labelEncoder.fit(Ztrain_raw)\n",
    "\n",
    "Ztrain = labelEncoder.transform(Ztrain_raw).toarray()\n",
    "Zvalid = labelEncoder.transform(Zvalid_raw).toarray()\n",
    "\n",
    "labels = np.array([['aanvraag'], ['other']])\n",
    "\n",
    "print()\n",
    "print('--- transform ---')\n",
    "print(f'labels:\\n{labels}')\n",
    "print(f'encoded:\\n{labelEncoder.transform(labels).toarray()}')\n",
    "\n",
    "print()\n",
    "print('--- inverse transform ---')\n",
    "example = [[1, 0.5]]\n",
    "print(f'inverse transform for example {example}: {labelEncoder.inverse_transform(example)}')\n",
    "\n",
    "print()\n",
    "print('--- transform on subset of data ---')\n",
    "print_count = 10  # examples to show\n",
    "print(f'Ztrain_raw[:{print_count}]:\\n{Ztrain_raw[:print_count]}')\n",
    "print('Ztrain:\\n', Ztrain[:print_count])\n",
    "\n",
    "print()\n",
    "print('--- transformation shapes ---')\n",
    "print('Ztrain_raw shape:\\t', Ztrain_raw.shape)\n",
    "print('Ztrain shape:\\t\\t', Ztrain.shape)\n",
    "print('Zvalid_raw shape:\\t', Ztrain_raw.shape)\n",
    "print('Zvalid shape:\\t\\t', Zvalid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = own_models.create_cnn(img_dim, num_classes=num_classes)\n",
    "model = own_models.create_cnn_g(img_dim, num_classes=num_classes, drop_chance=0.6)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "batch_size = 20\n",
    "epochs = 150\n",
    "\n",
    "class_weight = {\n",
    "    0: 1.0,  # aanvraag\n",
    "    1: 2.0,  # other error is x weight of aanvraag error (focus on learning recall)\n",
    "}\n",
    "\n",
    "run_name = '/massive_set_shuffle_split_aanvraag_1:1.2_heavy_aug_model_g_dropout_.6_lr.0003_nog_keer'\n",
    "LOG_DIR = f'./logs{run_name}'\n",
    "shutil.rmtree(LOG_DIR, ignore_errors=True)\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "#     zoom_range=0.1,        # randomly zoom into images\n",
    "#     rotation_range=10,      # randomly rotate images in the range (degrees, 0 to 180)\n",
    "#     width_shift_range=0.1, # randomly shift images horizontally (fraction of total width)\n",
    "#     height_shift_range=0.1,# randomly shift images vertically (fraction of total height)\n",
    "#     shear_range=2.0,  # in degrees\n",
    "#     channel_shift_range=0.1,\n",
    "#     horizontal_flip=False,  # randomly flip images\n",
    "#     vertical_flip=False    # randomly flip images\n",
    "    \n",
    "    # Heavy augmentation\n",
    "    zoom_range=0.15,        # randomly zoom into images\n",
    "    rotation_range=15,      # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.15, # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.15,# randomly shift images vertically (fraction of total height)\n",
    "    shear_range=4.0,  # in degrees\n",
    "    channel_shift_range=0.15,\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False    # randomly flip images\n",
    ")\n",
    "\n",
    "tbCallBack = keras.callbacks.TensorBoard(\n",
    "    log_dir=LOG_DIR,\n",
    "    histogram_freq=0,\n",
    "    write_graph=True,\n",
    "    write_images=True\n",
    ")\n",
    "\n",
    "terminateCB = tf.keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "\n",
    "def is_binary(model):\n",
    "    n_classes = model.get_layer('output').output_shape[1]\n",
    "    return n_classes == 1\n",
    "    \n",
    "def compile_model(model):\n",
    "    assert(K.image_data_format() == 'channels_last')\n",
    "    \n",
    "#     if is_binary(model):\n",
    "#         loss= keras.losses.binary_crossentropy\n",
    "#     else:\n",
    "    loss=keras.losses.categorical_crossentropy\n",
    "    \n",
    "    model.compile(\n",
    "        loss=loss,\n",
    "#         optimizer=keras.optimizers.Adadelta(),\n",
    "#         optimizer='rmsprop',\n",
    "#         optimizer='sgd',\n",
    "#         optimizer=keras.optimizers.SGD(lr=0.01),\n",
    "#         optimizer=keras.optimizers.Adam(),        \n",
    "        optimizer=keras.optimizers.Adam(lr=0.0003),\n",
    "#         optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "#         optimizer=keras.optimizers.Adam(lr=0.00003),\n",
    "#         metrics=['accuracy', keras_metrics.recall()]\n",
    "        metrics=['accuracy', keras_metrics.binary_recall(label=0)]\n",
    "\n",
    "    )\n",
    "\n",
    "def train_gen(model, X_train, Z_train, X_valid, Z_valid, batch_size, epochs):\n",
    "    compile_model(model)\n",
    "\n",
    "    history = model.fit_generator(\n",
    "        datagen.flow(X_train,\n",
    "                     Z_train,\n",
    "                     batch_size=batch_size\n",
    "        ),\n",
    "        steps_per_epoch=int(np.ceil(X_train.shape[0] / float(batch_size))),\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_valid, Z_valid),\n",
    "        class_weight=class_weight,\n",
    "        workers=4,\n",
    "        callbacks=[tbCallBack, terminateCB]\n",
    "    )\n",
    "    return history\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "# Img data\n",
    "# model = own_models.create_cnn(img_dim, num_classes)\n",
    "# history = train(model, Xtrain[0], Ytrain, Xvalid[0], Yvalid, batch_size, epochs)\n",
    "history = train_gen(model, Xtrain, Ztrain, Xvalid, Zvalid, batch_size, epochs)\n",
    "\n",
    "show_train_curves(history)\n",
    "\n",
    "difference = time.time() - t0\n",
    "print(f'time: {round(difference, 2)} seconds == {round(difference/60.0, 2)} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_score = model.evaluate(Xtrain, Ztrain, verbose=1)\n",
    "print('Train loss:', round(train_score[0], 3))\n",
    "print(f'Train accuracy: {round(train_score[1] * 100, 2)}%')\n",
    "\n",
    "valid_score = model.evaluate(Xvalid, Zvalid, verbose=1)\n",
    "print('Test loss:', round(valid_score[0], 3))\n",
    "valid_acc_str = f'{round(valid_score[1] * 100, 2)}%'\n",
    "print(f'Test accuracy: {valid_acc_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"types: {classes}\")\n",
    "\n",
    "print(\"train predictions, truth\")\n",
    "predictions_train =  model.predict(Xtrain, verbose=1)\n",
    "show_prediction_list(predictions_train, Ztrain)\n",
    "\n",
    "print(\"test predictions, truth\")\n",
    "predictions_valid = model.predict(Xvalid, verbose=1)\n",
    "show_prediction_list(predictions_valid, Zvalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code to show specific image by index\n",
    "# idx = 11\n",
    "# id = Yvalid_raw[idx, 2]\n",
    "# image = Xvalid_raw[idx]\n",
    "# print(id)\n",
    "# show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"train set:\")\n",
    "show_prediction_images(\n",
    "    Xtrain_raw,\n",
    "    Ztrain,\n",
    "    predictions_train,\n",
    "    Ytrain_raw[:, 2],\n",
    "    labelEncoder,\n",
    "    10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"test set:\")\n",
    "show_prediction_images(\n",
    "    Xvalid_raw,\n",
    "    Zvalid,\n",
    "    predictions_valid,\n",
    "    Yvalid_raw[:, 2],\n",
    "    labelEncoder,\n",
    "    50\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, recall_score, accuracy_score\n",
    "\n",
    "conf_threshold = 0.60\n",
    "labels = ['aanvraag', 'other']\n",
    " \n",
    "\n",
    "def split_bool_arrays(predictions: np.ndarray, threshold, verbose=False):\n",
    "    assert predictions.shape[1] == 2, 'expecting binary prediction in one hot format'\n",
    "    \n",
    "    y_pred_conf = np.amax(predictions, axis=1)\n",
    "    \n",
    "    if verbose:\n",
    "        print(y_pred_conf.round(2)[:10])\n",
    "    \n",
    "    certain = y_pred_conf >= threshold\n",
    "    uncertain = np.invert(certain)\n",
    "    return [certain, uncertain]\n",
    "\n",
    "def split_uncertain(predictions: np.ndarray, threshold, elements, verbose=False):\n",
    "    \"\"\"\n",
    "    Split all elements into certain and uncertain buckets\n",
    "    \n",
    "    @return [[elem1_certain, elem1_uncertain], ...]\n",
    "    \"\"\"\n",
    "    for element in elements:\n",
    "        assert element.shape[0] == predictions.shape[0], 'number of an element not equal to number of predictions'\n",
    "    \n",
    "    [certain, uncertain] = split_bool_arrays(predictions, threshold, verbose=verbose)\n",
    "    \n",
    "    results = []\n",
    "    for element in elements:\n",
    "        certain_bucket = element[certain]\n",
    "        uncertain_bucket = element[uncertain]\n",
    "        results.append([certain_bucket, uncertain_bucket])\n",
    "    return results\n",
    "    \n",
    "results = split_uncertain(predictions_valid, conf_threshold, [Xvalid_raw, Yvalid_raw, Zvalid, predictions_valid])\n",
    "print('image certain shape: ', results[0][0].shape)\n",
    "print('image uncertain shape: ', results[0][1].shape)\n",
    "print('meta certain shape: ', results[1][0].shape)\n",
    "print('meta uncertain shape: ', results[1][1].shape)\n",
    "\n",
    "[\n",
    "    _, # img\n",
    "    _, # meta\n",
    "    Zvalid_buckets, # true\n",
    "    Zvalid_pred_buckets, # prediction\n",
    "] = results\n",
    "\n",
    "#\n",
    "\n",
    "def print_missing_types_error(unique_types: list, expected: list, name: str):\n",
    "    print(f'{name} samples do not reflect all types, recall, precision and T1 scores therefor do not make much sense.')\n",
    "    print(f'{name} types: {unique_types}, expected {expected}')\n",
    "    print('Classification report generation skipped.')\n",
    "\n",
    "\n",
    "def create_reports(y_true_oh: np.ndarray, y_pred_oh: np.ndarray):\n",
    "    assert y_true_oh.shape == y_pred_oh.shape\n",
    "    assert y_true_oh.shape[1] == 2, 'expecting binary one hot inputs'\n",
    "    y_true = labelEncoder.inverse_transform(y_true_oh)\n",
    "    y_pred = labelEncoder.inverse_transform(y_pred_oh)\n",
    "    \n",
    "    is_correct=y_true == y_pred\n",
    "    \n",
    "    y_true_pd = pd.Series(y_true.ravel())\n",
    "    y_pred_pd = pd.Series(y_pred.ravel())\n",
    "    crosstab = pd.crosstab(y_true_pd, y_pred_pd, rownames=['Actual'], colnames=['Predicted'], margins=True, margins_name='Total')\n",
    "    \n",
    "    report = None\n",
    "    true_types = np.unique(y_true_pd)\n",
    "    pred_types = np.unique(y_pred_pd)\n",
    "    if len(true_types) < len(labels):\n",
    "        print_missing_types_error(true_types, labels, 'True')\n",
    "    elif len(pred_types) < len(labels):\n",
    "        print_missing_types_error(pred_types, labels, 'Pred')\n",
    "    else:\n",
    "        report = classification_report(y_true, y_pred, labels=labels)\n",
    "\n",
    "    return [crosstab, report, is_correct]\n",
    "\n",
    "\n",
    "def show_reports(y_true_oh: np.ndarray, y_pred_oh: np.ndarray):\n",
    "    if len(y_true_oh) == 0 or len(y_pred_oh) == 0:\n",
    "        print(\"No results to show\")\n",
    "        return\n",
    "    [crosstab, report, is_correct] = create_reports(y_true_oh, y_pred_oh)\n",
    "    print(crosstab)\n",
    "    \n",
    "    if (report):\n",
    "        print()\n",
    "        print(report)\n",
    "    \n",
    "    return is_correct\n",
    "    \n",
    "\n",
    "print()\n",
    "print('--- certain bucket ---')\n",
    "show_reports(Zvalid_buckets[0], Zvalid_pred_buckets[0])\n",
    "\n",
    "print()\n",
    "print('--- uncertain bucket ---')\n",
    "show_reports(Zvalid_buckets[1], Zvalid_pred_buckets[1])\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "\n",
    "\n",
    "class color:\n",
    "   PURPLE = '\\033[95m'\n",
    "   CYAN = '\\033[96m'\n",
    "   DARKCYAN = '\\033[36m'\n",
    "   BLUE = '\\033[94m'\n",
    "   GREEN = '\\033[92m'\n",
    "   YELLOW = '\\033[93m'\n",
    "   RED = '\\033[91m'\n",
    "   BOLD = '\\033[1m'\n",
    "   UNDERLINE = '\\033[4m'\n",
    "   END = '\\033[0m'\n",
    "\n",
    "\n",
    "predictions = predictions_valid\n",
    "\n",
    "def show_results(threshold):\n",
    "    ids = Yvalid_raw[:, 2]\n",
    "    total = predictions.shape[0]\n",
    "    [certain, uncertain] = split_bool_arrays(predictions, threshold)\n",
    "    certain_count = np.sum(certain)\n",
    "    uncertain_count = np.sum(uncertain)\n",
    "    \n",
    "    # Show counts of split\n",
    "    certain_percentage = certain_count/total*100\n",
    "    uncertain_percentage = uncertain_count/total*100\n",
    "    counts_df = pd.DataFrame([\n",
    "        [certain_count, uncertain_count, total],\n",
    "        [certain_percentage, uncertain_percentage, 100.0]\n",
    "    ],\n",
    "                      columns=['certain', 'uncertain', 'total'],\n",
    "                      index=['absolute', 'relative'])\n",
    "    \n",
    "    # Show metrics of splits\n",
    "    [\n",
    "        Ytrue_buckets,\n",
    "        Ypred_buckets,\n",
    "        ids_buckets,\n",
    "    ] = split_uncertain(predictions, threshold, [Zvalid, predictions_valid, ids])\n",
    "    \n",
    "    \n",
    "    certain_not_empty = Ytrue_buckets[0].shape[0] > 0\n",
    "    if certain_not_empty:\n",
    "        y_true = labelEncoder.inverse_transform(Ytrue_buckets[0])\n",
    "        y_pred = labelEncoder.inverse_transform(Ypred_buckets[0])\n",
    "        certain_accuracy = accuracy_score(y_true, y_pred)\n",
    "        certain_recall = recall_score(y_true, y_pred, pos_label='aanvraag')    \n",
    "        print(f'certain examples:\\t\\t{color.BOLD}{round(certain_percentage, 1)}%{color.END}', end='')\n",
    "        print(f'\\t accuracy: {color.BOLD}{round(certain_accuracy*100, 2)}%{color.END}', end='')\n",
    "        print(f', aanvraag recall: {color.BOLD}{round(certain_recall*100, 2)}%{color.END}')\n",
    "        \n",
    "    else:\n",
    "        print(f'certain examples:\\t\\t{color.BOLD}{round(certain_percentage, 1)}%{color.END}')\n",
    "    print(f'uncertain examples:\\t\\t{color.BOLD}{round(uncertain_percentage, 1)}%{color.END}')\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print(counts_df.round(2))\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print(f'{color.BOLD}## Certain examples{color.END}')\n",
    "    if certain_not_empty:\n",
    "        certain_is_correct = show_reports(Ytrue_buckets[0], Ypred_buckets[0])\n",
    "    else:\n",
    "        print('no data')\n",
    "\n",
    "    print()\n",
    "    print()\n",
    "    print(f'{color.BOLD}## Uncertain examples{color.END}')\n",
    "    if Ytrue_buckets[1].shape[0] == 0:\n",
    "        print('no data')\n",
    "    else:\n",
    "        uncertain_is_correct = show_reports(Ytrue_buckets[1], Ypred_buckets[1])\n",
    "    \n",
    "    print()\n",
    "    print()\n",
    "    print(f'{color.BOLD}## Certain errors{color.END}')\n",
    "    certain_ids = ids_buckets[0]\n",
    "    certain_ids.shape = (certain_ids.size, 1)\n",
    "    certain_is_incorrect = np.invert(certain_is_correct)\n",
    "    \n",
    "    show_max = 50\n",
    "    incorrect = certain_ids[certain_is_incorrect]\n",
    "    print(f'incorrect ids[:{show_max}]:')\n",
    "    print('\\n'.join(incorrect[:show_max]))\n",
    "\n",
    "\n",
    "widget = widgets.FloatSlider(\n",
    "    value=0.9,\n",
    "    min=0.5,\n",
    "    max=1.0,\n",
    "    step=0.005,\n",
    "    continuous_update=False,\n",
    "    description='Threshold:',\n",
    "    readout=True,\n",
    "    readout_format='.3f',\n",
    ")\n",
    "\n",
    "interact(show_results, threshold=widget);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output / persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions_overview(Y_oh, pred_oh, references, encoder):\n",
    "    Y_class = encoder.inverse_transform(Y_oh)\n",
    "    pred_class = encoder.inverse_transform(pred_oh)\n",
    "    \n",
    "    data = {'reference': references, 'label': Y_class[:, 0], 'prediction': pred_class[:, 0]}\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    return df\n",
    "\n",
    "DIR = './output'\n",
    "os.makedirs(DIR, exist_ok=True)\n",
    "\n",
    "df = predictions_overview(Ztrain, predictions_train, Ytrain_raw[:, 2], labelEncoder)\n",
    "df.to_csv(os.path.join(DIR, 'train_predictions.csv'))\n",
    "print('--- Train ---')\n",
    "print(df)\n",
    "\n",
    "df = predictions_overview(Zvalid, predictions_valid, Yvalid_raw[:, 2], labelEncoder)\n",
    "df.to_csv(os.path.join(DIR, 'validation_predictions.csv'))\n",
    "print('--- Validation ---')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('writing image encoder to disk')\n",
    "imageEncoder.save(TRANSFORM_DIR)\n",
    "\n",
    "print('writing label encoder to disk')\n",
    "labelEncoder.save(TRANSFORM_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_model(model, directory):\n",
    "    model_json = model.to_json()\n",
    "    json_path = os.path.join(directory, \"model.json\")\n",
    "    weights_path = os.path.join(directory, \"weights.h5\")\n",
    "    with open(json_path, \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    model.save_weights(weights_path)\n",
    "\n",
    "write_model(model, MODEL_DIR)\n",
    "print(f\"Model written to {MODEL_DIR}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
