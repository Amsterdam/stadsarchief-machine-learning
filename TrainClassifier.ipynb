{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic classification of stadsarchief images\n",
    "Network based on: https://towardsdatascience.com/build-your-own-convolution-neural-network-in-5-mins-4217c2cf964f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from PIL import Image\n",
    "from scipy import misc\n",
    "import keras.backend as K\n",
    "\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.initializers import RandomUniform\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "from stats import list_stats\n",
    "from data import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first few ids: ['000000091010', '000000091053', '000000091089', '000000091123', '000000091242']\n",
      "shuffling X and Y\n"
     ]
    }
   ],
   "source": [
    "# IMG_DIR = 'examples/0-src/200x200/';\n",
    "# LABEL_DIR = 'examples/0-src/labels/';\n",
    "IMG_DIR = 'examples/0-src/beeldbank-scraped_set/50x50/'\n",
    "LABEL_DIR = 'examples/0-src/beeldbank-scraped_set/labels/'\n",
    "img_dim = (50, 50, 3);\n",
    "\n",
    "[X, Y_yaml] = load_data(IMG_DIR, LABEL_DIR)\n",
    "Y_type = np.array([y.get('type') for y in Y_yaml])\n",
    "\n",
    "def shuffle(X, Y):\n",
    "    indices = np.random.permutation(X.shape[0])\n",
    "    X_shuffled = X[indices]\n",
    "    Y_shuffled = Y[indices]\n",
    "    return (X_shuffled, Y_shuffled)\n",
    "# print(X.shape)\n",
    "\n",
    "print('shuffling X and Y')\n",
    "X_shuffled, Y_shuffled = shuffle(X, Y_type)\n",
    "X = X_shuffled\n",
    "Y_type = Y_shuffled\n",
    "\n",
    "# def simplify_Y(Y):\n",
    "#     return np.array([y if y == 'blueprint' else 'other' for y in Y])\n",
    "\n",
    "# Y_type = simplify_Y(Y_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape X: (1201, 50, 50, 3)\n",
      "shape Y: (1201,)\n",
      "classes: 5\n",
      "> 5 count classes: [['bouwtekening', 338], ['foto', 250], ['kaart', 30], ['prent', 575], ['affiche', 8]]\n",
      "largest class: prent, count: 575\n",
      "total count: 1201\n",
      "score to beat: 0.4787676935886761\n"
     ]
    }
   ],
   "source": [
    "print(f\"shape X: {X.shape}\")\n",
    "print(f\"shape Y: {Y_type.shape}\")\n",
    "\n",
    "list_stats(Y_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes: 5\n",
      "types encountered: ['bouwtekening', 'foto', 'kaart', 'prent', 'affiche']\n",
      "['prent' 'prent' 'foto']\n",
      "[3 3 1]\n",
      "classes: 5\n",
      "> 5 count classes: [[0, 338], [1, 250], [2, 30], [3, 575], [4, 8]]\n",
      "largest class: 3, count: 575\n",
      "total count: 1201\n",
      "score to beat: 0.4787676935886761\n"
     ]
    }
   ],
   "source": [
    "# Convert string to idx\n",
    "types = list(set(Y_type))\n",
    "num_classes = len(types)\n",
    "print(f\"number of classes: {num_classes}\")\n",
    "print(f\"types encountered: {types}\")\n",
    "\n",
    "def convert_to_index(Y, types):\n",
    "    return np.array([types.index(y) for y in Y])\n",
    "\n",
    "Yind = convert_to_index(Y_type, types)\n",
    "print(Y_type[:3])\n",
    "print(Yind[:3])\n",
    "\n",
    "list_stats(Yind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_class(Y, class_idx):\n",
    "#     print(Y)\n",
    "#     Y[:] = class_idx\n",
    "#     print(Y)\n",
    "#     return Y\n",
    "# # YInd = set_class(Yind, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1201,)\n",
      "(1201, 5)\n"
     ]
    }
   ],
   "source": [
    "Y = keras.utils.to_categorical(Yind, num_classes)  # convert class vectors to binary class matrices\n",
    "print(Yind.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "split data shapes:\n",
      "(960, 50, 50, 3)\n",
      "(960, 5)\n",
      "(241, 50, 50, 3)\n",
      "(241, 5)\n"
     ]
    }
   ],
   "source": [
    "# Split to train and test\n",
    "def split_data(X, Y, size):\n",
    "    X_train = X[:N]\n",
    "    Y_train = Y[:N]\n",
    "    X_test = X[N:]\n",
    "    Y_test = Y[N:]\n",
    "    return (X_train, Y_train), (X_test, Y_test)\n",
    "\n",
    "total = X.shape[0]\n",
    "N = math.floor(0.8 * total)\n",
    "(X_train, Y_train), (X_test, Y_test) = split_data(X, Y, N)\n",
    "print(\"\")\n",
    "print(\"split data shapes:\")\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stats train: \n",
      "stats test: \n"
     ]
    }
   ],
   "source": [
    "print(\"stats train: \")\n",
    "# list_stats(Y_train)\n",
    "print(\"stats test: \")\n",
    "# list_stats(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split data shapes:\n",
      "(960, 50, 50, 3)\n",
      "(960, 5)\n",
      "(241, 50, 50, 3)\n",
      "(241, 5)\n",
      "split data shapes:\n",
      "(960, 40, 40, 3)\n",
      "(960, 5)\n",
      "(241, 40, 40, 3)\n",
      "(241, 5)\n"
     ]
    }
   ],
   "source": [
    "# resize = 40\n",
    "# print(\"split data shapes:\")\n",
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(Y_test.shape)\n",
    "# X_train = X_train[:, :resize, :resize, :]\n",
    "# X_test = X_test[:, :resize, :resize, :]\n",
    "# print(\"split data shapes:\")\n",
    "# print(X_train.shape)\n",
    "# print(Y_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(Y_test.shape)\n",
    "# img_dim = (resize, resize, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 40, 3)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 38, 38, 2)         56        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 38, 38, 2)         0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2888)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 16)                46224     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 5)                 85        \n",
      "=================================================================\n",
      "Total params: 46,365\n",
      "Trainable params: 46,365\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# def build_model(num_classes, img_dim):\n",
    "#     model = Sequential()\n",
    "#     model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "#                      activation='relu',\n",
    "#                      input_shape=img_dim))\n",
    "#     model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "#     model.add(Flatten())\n",
    "#     model.add(Dense(128, activation='relu'))\n",
    "#     model.add(Dropout(0.5))\n",
    "#     model.add(Dense(num_classes, activation='softmax'))\n",
    "#     return model\n",
    "\n",
    "def build_model(num_classes, img_dim):\n",
    "    print(img_dim)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(2, kernel_size=(3, 3),\n",
    "                     activation='linear',\n",
    "                     input_shape=img_dim,\n",
    "                     kernel_initializer = RandomUniform()\n",
    "                    ))\n",
    "    model.add(LeakyReLU())\n",
    "#     model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#     model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Flatten())    \n",
    "#     model.add(Flatten(input_shape=img_dim))\n",
    "    model.add(Dense(16, activation='linear', kernel_initializer = RandomUniform()))\n",
    "    model.add(LeakyReLU())\n",
    "#     model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "model = build_model(num_classes, img_dim)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 960 samples, validate on 241 samples\n",
      "Epoch 1/50\n",
      "960/960 [==============================] - 1s 802us/step - loss: 11.9339 - acc: 0.2208 - val_loss: 11.2486 - val_acc: 0.2988\n",
      "Epoch 2/50\n",
      "960/960 [==============================] - 0s 194us/step - loss: 11.5193 - acc: 0.2771 - val_loss: 10.7902 - val_acc: 0.2988\n",
      "Epoch 3/50\n",
      "960/960 [==============================] - 0s 192us/step - loss: 8.9130 - acc: 0.2240 - val_loss: 6.0821 - val_acc: 0.0996\n",
      "Epoch 4/50\n",
      "960/960 [==============================] - 0s 187us/step - loss: 4.5103 - acc: 0.2542 - val_loss: 3.0154 - val_acc: 0.3320\n",
      "Epoch 5/50\n",
      "960/960 [==============================] - 0s 193us/step - loss: 2.3985 - acc: 0.3406 - val_loss: 2.1774 - val_acc: 0.3942\n",
      "Epoch 6/50\n",
      "960/960 [==============================] - 0s 190us/step - loss: 1.9625 - acc: 0.4802 - val_loss: 1.8115 - val_acc: 0.3817\n",
      "Epoch 7/50\n",
      "960/960 [==============================] - 0s 193us/step - loss: 1.5708 - acc: 0.4615 - val_loss: 1.7068 - val_acc: 0.4855\n",
      "Epoch 8/50\n",
      "960/960 [==============================] - 0s 191us/step - loss: 1.5300 - acc: 0.4948 - val_loss: 1.6113 - val_acc: 0.4108\n",
      "Epoch 9/50\n",
      "960/960 [==============================] - 0s 194us/step - loss: 1.3933 - acc: 0.5167 - val_loss: 1.5660 - val_acc: 0.4232\n",
      "Epoch 10/50\n",
      "960/960 [==============================] - 0s 191us/step - loss: 1.3326 - acc: 0.5385 - val_loss: 1.4643 - val_acc: 0.5477\n",
      "Epoch 11/50\n",
      "960/960 [==============================] - 0s 192us/step - loss: 1.2787 - acc: 0.5844 - val_loss: 1.4023 - val_acc: 0.4772\n",
      "Epoch 12/50\n",
      "960/960 [==============================] - 0s 200us/step - loss: 1.2016 - acc: 0.5677 - val_loss: 1.3588 - val_acc: 0.5021\n",
      "Epoch 13/50\n",
      "960/960 [==============================] - 0s 195us/step - loss: 1.1502 - acc: 0.6240 - val_loss: 1.2839 - val_acc: 0.5809\n",
      "Epoch 14/50\n",
      "960/960 [==============================] - 0s 199us/step - loss: 1.1106 - acc: 0.6229 - val_loss: 1.2462 - val_acc: 0.5228\n",
      "Epoch 15/50\n",
      "960/960 [==============================] - 0s 199us/step - loss: 1.0636 - acc: 0.6552 - val_loss: 1.2121 - val_acc: 0.6183\n",
      "Epoch 16/50\n",
      "960/960 [==============================] - 0s 206us/step - loss: 1.0278 - acc: 0.6677 - val_loss: 1.1867 - val_acc: 0.6058\n",
      "Epoch 17/50\n",
      "960/960 [==============================] - 0s 197us/step - loss: 0.9894 - acc: 0.6937 - val_loss: 1.1334 - val_acc: 0.6515\n",
      "Epoch 18/50\n",
      "960/960 [==============================] - 0s 202us/step - loss: 0.9535 - acc: 0.6990 - val_loss: 1.1215 - val_acc: 0.6639\n",
      "Epoch 19/50\n",
      "960/960 [==============================] - 0s 201us/step - loss: 0.9225 - acc: 0.7208 - val_loss: 1.0856 - val_acc: 0.6680\n",
      "Epoch 20/50\n",
      "960/960 [==============================] - 0s 196us/step - loss: 0.8995 - acc: 0.7146 - val_loss: 1.0641 - val_acc: 0.6598\n",
      "Epoch 21/50\n",
      "960/960 [==============================] - 0s 210us/step - loss: 0.8758 - acc: 0.7385 - val_loss: 1.0634 - val_acc: 0.6266\n",
      "Epoch 22/50\n",
      "960/960 [==============================] - 0s 196us/step - loss: 0.8421 - acc: 0.7396 - val_loss: 1.0208 - val_acc: 0.6888\n",
      "Epoch 23/50\n",
      "960/960 [==============================] - 0s 203us/step - loss: 0.8120 - acc: 0.7427 - val_loss: 0.9918 - val_acc: 0.7012\n",
      "Epoch 24/50\n",
      "960/960 [==============================] - 0s 202us/step - loss: 0.7794 - acc: 0.7729 - val_loss: 0.9820 - val_acc: 0.6929\n",
      "Epoch 25/50\n",
      "960/960 [==============================] - 0s 208us/step - loss: 0.7556 - acc: 0.7615 - val_loss: 0.9857 - val_acc: 0.7095\n",
      "Epoch 26/50\n",
      "960/960 [==============================] - 0s 200us/step - loss: 0.7269 - acc: 0.7844 - val_loss: 0.9822 - val_acc: 0.6473\n",
      "Epoch 27/50\n",
      "960/960 [==============================] - 0s 202us/step - loss: 0.7248 - acc: 0.7760 - val_loss: 0.9190 - val_acc: 0.7469\n",
      "Epoch 28/50\n",
      "960/960 [==============================] - 0s 216us/step - loss: 0.6832 - acc: 0.7948 - val_loss: 0.8886 - val_acc: 0.7427\n",
      "Epoch 29/50\n",
      "960/960 [==============================] - 0s 200us/step - loss: 0.6442 - acc: 0.8156 - val_loss: 0.8594 - val_acc: 0.7344\n",
      "Epoch 30/50\n",
      "960/960 [==============================] - 0s 205us/step - loss: 0.6062 - acc: 0.8333 - val_loss: 0.8534 - val_acc: 0.7469\n",
      "Epoch 31/50\n",
      "960/960 [==============================] - 0s 208us/step - loss: 0.5729 - acc: 0.8479 - val_loss: 0.8240 - val_acc: 0.7344\n",
      "Epoch 32/50\n",
      "960/960 [==============================] - 0s 204us/step - loss: 0.5484 - acc: 0.8573 - val_loss: 0.8417 - val_acc: 0.7593\n",
      "Epoch 33/50\n",
      "960/960 [==============================] - 0s 210us/step - loss: 0.5471 - acc: 0.8604 - val_loss: 0.8595 - val_acc: 0.7510\n",
      "Epoch 34/50\n",
      "960/960 [==============================] - 0s 209us/step - loss: 0.5422 - acc: 0.8563 - val_loss: 0.8352 - val_acc: 0.7676\n",
      "Epoch 35/50\n",
      "960/960 [==============================] - 0s 213us/step - loss: 0.5147 - acc: 0.8708 - val_loss: 0.8082 - val_acc: 0.7469\n",
      "Epoch 36/50\n",
      "960/960 [==============================] - 0s 220us/step - loss: 0.5147 - acc: 0.8635 - val_loss: 0.8538 - val_acc: 0.7676\n",
      "Epoch 37/50\n",
      "960/960 [==============================] - 0s 216us/step - loss: 0.5136 - acc: 0.8708 - val_loss: 0.8077 - val_acc: 0.7510\n",
      "Epoch 38/50\n",
      "960/960 [==============================] - 0s 214us/step - loss: 0.4979 - acc: 0.8750 - val_loss: 0.8411 - val_acc: 0.7676\n",
      "Epoch 39/50\n",
      "960/960 [==============================] - 0s 223us/step - loss: 0.4870 - acc: 0.8760 - val_loss: 0.7926 - val_acc: 0.7552\n",
      "Epoch 40/50\n",
      "960/960 [==============================] - 0s 219us/step - loss: 0.4727 - acc: 0.8833 - val_loss: 0.8114 - val_acc: 0.7842\n",
      "Epoch 41/50\n",
      "960/960 [==============================] - 0s 215us/step - loss: 0.4662 - acc: 0.8854 - val_loss: 0.7912 - val_acc: 0.7635\n",
      "Epoch 42/50\n",
      "960/960 [==============================] - 0s 210us/step - loss: 0.4506 - acc: 0.8927 - val_loss: 0.8052 - val_acc: 0.7718\n",
      "Epoch 43/50\n",
      "960/960 [==============================] - 0s 216us/step - loss: 0.4520 - acc: 0.8937 - val_loss: 0.7888 - val_acc: 0.7759\n",
      "Epoch 44/50\n",
      "960/960 [==============================] - 0s 211us/step - loss: 0.4427 - acc: 0.9010 - val_loss: 0.8143 - val_acc: 0.7842\n",
      "Epoch 45/50\n",
      "960/960 [==============================] - 0s 205us/step - loss: 0.4381 - acc: 0.9010 - val_loss: 0.7805 - val_acc: 0.7759\n",
      "Epoch 46/50\n",
      "960/960 [==============================] - 0s 215us/step - loss: 0.4253 - acc: 0.9010 - val_loss: 0.7907 - val_acc: 0.7801\n",
      "Epoch 47/50\n",
      "960/960 [==============================] - 0s 211us/step - loss: 0.4171 - acc: 0.9063 - val_loss: 0.7801 - val_acc: 0.7718\n",
      "Epoch 48/50\n",
      "960/960 [==============================] - 0s 214us/step - loss: 0.4134 - acc: 0.9073 - val_loss: 0.7890 - val_acc: 0.7801\n",
      "Epoch 49/50\n",
      "960/960 [==============================] - 0s 210us/step - loss: 0.4102 - acc: 0.9073 - val_loss: 0.7814 - val_acc: 0.7759\n",
      "Epoch 50/50\n",
      "960/960 [==============================] - 0s 218us/step - loss: 0.4016 - acc: 0.9104 - val_loss: 0.7891 - val_acc: 0.7842\n"
     ]
    }
   ],
   "source": [
    "batch_size = 200\n",
    "epochs = 50\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return K.mean(y_pred)\n",
    "\n",
    "def train(model, X_train, Y_train, X_test, Y_test, batch_size, epochs):\n",
    "    model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "#               optimizer=keras.optimizers.Adadelta(),\n",
    "             optimizer=keras.optimizers.Adam(\n",
    "                 lr=0.0003,\n",
    "# #                  lr=1e-2,\n",
    "# #                  epsilon=1e-6\n",
    "             ),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "    model.fit(X_train, Y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=1,\n",
    "              \n",
    "    validation_data=(X_test, Y_test))\n",
    "train(model, X_train, Y_train, X_test, Y_test, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.04810360854802032\n",
      "Train accuracy: 0.9958333333333333\n",
      "Test loss: 1.019663213694244\n",
      "Test accuracy: 0.8049792541013219\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_train, Y_train, verbose=0)\n",
    "print('Train loss:', score[0])\n",
    "print('Train accuracy:', score[1])\n",
    "\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "types: ['bouwtekening', 'foto', 'kaart', 'prent', 'affiche']\n",
      "train predictions, truth\n",
      "[3 3 1 1 1 1 0 3 3 0 3 3 3 3 3 0 3 3 3 3 3 3 3 3 0 3 3 0 3 3]\n",
      "[3 3 1 1 1 1 0 3 3 0 3 3 3 3 3 0 3 3 3 3 3 3 3 3 0 3 3 0 3 3]\n",
      "test predictions, truth\n",
      "[0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9\n",
      "[0 0 1 0 3 3 3 3 1 0 3 1 3 3 0 0 0 0 1 3 2 3 3 0 3 3 0 0 0 0]\n",
      "[0 0 1 0 3 3 1 3 1 0 3 0 3 3 0 1 0 0 1 3 0 3 3 1 3 1 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "show_cnt = 30\n",
    "print(f\"types: {types}\")\n",
    "\n",
    "print(\"train predictions, truth\")\n",
    "print(model.predict_classes(X_train)[:show_cnt])\n",
    "print(np.argmax(Y_train, axis=1)[:show_cnt])\n",
    "\n",
    "print(\"test predictions, truth\")\n",
    "print('[' + ' '.join(str(x)[-1:] for x in range(show_cnt)) )\n",
    "print(model.predict_classes(X_test)[:show_cnt])\n",
    "print(np.argmax(Y_test, axis=1)[:show_cnt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show_image(data, idx):\n",
    "    image=X_train[idx, :, :, :]\n",
    "#     print(image.shape)\n",
    "#     img = Image.fromarray(image, 'RGB')\n",
    "#     img.show()\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(X_test, 11)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
